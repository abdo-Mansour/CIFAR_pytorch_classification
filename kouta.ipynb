{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.drop_conv = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.cnn2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 5, padding = 2)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.cnn3 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 5, padding = 2)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.conv3_bn = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Hidden layer 1\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 1000) \n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "        self.fc1_bn = nn.BatchNorm1d(1000)\n",
    "        \n",
    "        # Hidden layer 2\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.fc2_bn = nn.BatchNorm1d(1000)\n",
    "\n",
    "        # Hidden layer 3\n",
    "        self.fc3 = nn.Linear(1000, 1000)\n",
    "        self.fc3_bn = nn.BatchNorm1d(1000)\n",
    "        \n",
    "        # Hidden layer 4\n",
    "        self.fc4 = nn.Linear(1000, 1000)\n",
    "        self.fc4_bn = nn.BatchNorm1d(1000)\n",
    "        \n",
    "        # Final layer\n",
    "        self.fc5 = nn.Linear(1000, 10)\n",
    "        self.fc5_bn = nn.BatchNorm1d(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = self.conv1_bn(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.drop_conv(x)\n",
    "        \n",
    "        x = self.cnn2(x)\n",
    "        x = self.conv2_bn(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.drop_conv(x)\n",
    "        \n",
    "        x = self.cnn3(x)\n",
    "        x = self.conv3_bn(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.drop_conv(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc1_bn(x)\n",
    "        x = F.relu(self.drop(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc2_bn(x)\n",
    "        \n",
    "        x = F.relu(self.drop(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc3_bn(x)\n",
    "        x = F.relu(self.drop(x))\n",
    "        x = self.fc4(x)\n",
    "        x = self.fc4_bn(x)\n",
    "        x = F.relu(self.drop(x))\n",
    "        x = self.fc5(x)\n",
    "        x = self.fc5_bn(x)   \n",
    "        return(x)\n",
    "model = ConvNet().to(device)\n",
    "num_epochs = 20\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "    print(f'[{epoch + 1}] loss: {running_loss / n_total_steps:.3f}')\n",
    "print('Finished Training')\n",
    "PATH = './cnn.pth'\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_accuracy(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Get predicted labels\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Count correct predictions\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Count total predictions\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\\"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
